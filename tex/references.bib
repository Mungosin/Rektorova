@misc{itseez2015opencv,
	title={Open Source Computer Vision Library},
	author={Itseez},
	year={2015},
	howpublished = {\url{https://github.com/itseez/opencv}}
}

@misc{tensorflow2015-whitepaper,
	title={ {TensorFlow}: Large-Scale Machine Learning on Heterogeneous Systems},
	url={https://www.tensorflow.org/},
	note={Software available from tensorflow.org},
	author={
	Mart\'{\i}n~Abadi and
	Ashish~Agarwal and
	Paul~Barham and
	Eugene~Brevdo and
	Zhifeng~Chen and
	Craig~Citro and
	Greg~S.~Corrado and
	Andy~Davis and
	Jeffrey~Dean and
	Matthieu~Devin and
	Sanjay~Ghemawat and
	Ian~Goodfellow and
	Andrew~Harp and
	Geoffrey~Irving and
	Michael~Isard and
	Yangqing Jia and
	Rafal~Jozefowicz and
	Lukasz~Kaiser and
	Manjunath~Kudlur and
	Josh~Levenberg and
	Dandelion~Man\'{e} and
	Rajat~Monga and
	Sherry~Moore and
	Derek~Murray and
	Chris~Olah and
	Mike~Schuster and
	Jonathon~Shlens and
	Benoit~Steiner and
	Ilya~Sutskever and
	Kunal~Talwar and
	Paul~Tucker and
	Vincent~Vanhoucke and
	Vijay~Vasudevan and
	Fernanda~Vi\'{e}gas and
	Oriol~Vinyals and
	Pete~Warden and
	Martin~Wattenberg and
	Martin~Wicke and
	Yuan~Yu and
	Xiaoqiang~Zheng},
	year={2015},
}

@inproceedings{NMSLIB,
	author    = {Leonid Boytsov and
	Bilegsaikhan Naidan},
	title     = {Engineering Efficient and Effective Non-metric Space Library},
	booktitle = {Similarity Search and Applications - 6th International Conference,
	{SISAP} 2013, {A} Coru{\~{n}}a, Spain, October 2-4, 2013, Proceedings},
	pages     = {280--293},
	year      = {2013},
	crossref  = {DBLP:conf/sisap/2013},
	url       = {https://doi.org/10.1007/978-3-642-41062-8_28},
	doi       = {10.1007/978-3-642-41062-8_28},
	timestamp = {Thu, 25 May 2017 00:42:36 +0200},
	biburl    = {https://dblp.org/rec/bib/conf/sisap/BoytsovN13},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{TSNE,
	added-at = {2015-06-19T12:07:15.000+0200},
	author = {van der Maaten, Laurens and Hinton, Geoffrey},
	biburl = {https://www.bibsonomy.org/bibtex/28b9aebb404ad4a4c6a436ea413550b30/lopusz_kdd},
	interhash = {370ba8b9e1909b61880a6f47c93bcd49},
	intrahash = {8b9aebb404ad4a4c6a436ea413550b30},
	journal = {Journal of Machine Learning Research},
	keywords = {dimensionality_reduction tSNE visualization},
	pages = {2579--2605},
	timestamp = {2015-08-19T15:19:11.000+0200},
	title = {Visualizing Data using {t-SNE} },
	url = {http://www.jmlr.org/papers/v9/vandermaaten08a.html},
	volume = 9,
	year = 2008
}

@InProceedings{STL10,
	title = 	 {An Analysis of Single-Layer Networks in Unsupervised Feature Learning},
	author = 	 {Adam Coates and Andrew Ng and Honglak Lee},
	booktitle = 	 {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics},
	pages = 	 {215--223},
	year = 	 {2011},
	editor = 	 {Geoffrey Gordon and David Dunson and Miroslav Dudík},
	volume = 	 {15},
	series = 	 {Proceedings of Machine Learning Research},
	address = 	 {Fort Lauderdale, FL, USA},
	month = 	 {11--13 Apr},
	publisher = 	 {PMLR},
	pdf = 	 {http://proceedings.mlr.press/v15/coates11a/coates11a.pdf},
	url = 	 {http://proceedings.mlr.press/v15/coates11a.html},
	abstract = 	 {A great deal of research has focused on algorithms for learning features from unlabeled data. Indeed, much progress has been made on benchmark datasets like NORB and CIFAR-10 by employing increasingly complex unsupervised learning algorithms and deep models. In this paper, however, we show that several simple factors, such as the number of hidden nodes in the model, may be more important to achieving high performance than the learning algorithm or the depth of the model. Specifically, we will apply several off-the-shelf feature learning algorithms (sparse auto-encoders, sparse RBMs, K-means clustering, and Gaussian mixtures) to CIFAR-10, NORB, and STL datasets using only single-layer networks. We then present a detailed analysis of the effect of changes in the model setup: the receptive field size, number of hidden nodes (features), the step-size (“stride”) between extracted features, and the effect of whitening. Our results show that large numbers of hidden nodes and dense feature extraction are critical to achieving high performance - so critical, in fact, that when these parameters are pushed to their limits, we achieve state-of-the-art performance on both CIFAR-10 and NORB using only a single layer of features. More surprisingly, our best performance is based on K-means clustering, which is extremely fast, has no hyper-parameters to tune beyond the model structure itself, and is very easy to implement. Despite the simplicity of our system, we achieve accuracy beyond all previously published results on the CIFAR-10 and NORB datasets (79.6% and 97.2% respectively).  [pdf]}
}

@article{openimages,
	title={OpenImages: A public dataset for large-scale multi-label and multi-class image classification.},
	author={Krasin, Ivan and Duerig, Tom and Alldrin, Neil and Ferrari, Vittorio and Abu-El-Haija, Sami and Kuznetsova, Alina and Rom, Hassan and Uijlings, Jasper and Popov, Stefan and Veit, Andreas and Belongie, Serge and Gomes, Victor and Gupta, Abhinav and Sun, Chen and Chechik, Gal and Cai, David and Feng, Zheyun and Narayanan, Dhyanesh and Murphy, Kevin},
	journal={Dataset available from https://github.com/openimages},
	year={2017}
}

@INPROCEEDINGS{VectorSimilarity, 
	author={A. Heidarian and M. J. Dinneen}, 
	booktitle={2016 IEEE Second International Conference on Big Data Computing Service and Applications (BigDataService)}, 
	title={A Hybrid Geometric Approach for Measuring Similarity Level Among Documents and Document Clustering}, 
	year={2016}, 
	volume={}, 
	number={}, 
	pages={142-151}, 
	keywords={geometry;pattern clustering;query processing;recommender systems;text analysis;Euclidean distance;TS-SS;clustering purity;content analysis;cosine similarity;document clustering;geometric criteria;geometrical similarity measures;hybrid geometric approach;nongeometrical similarity measures;recommendation systems;search query;similarity level;similarity level measurement;textual documents;Computational modeling;Correlation;Current measurement;Euclidean distance;Extraterrestrial measurements;Frequency measurement;Semantics;Document Clustering;Document Similarity;Geometric Similarity;Similarity Level;VSM}, 
	doi={10.1109/BigDataService.2016.14}, 
	ISSN={}, 
	month={March},}

@article{PCA,
	author    = {Jonathon Shlens},
	title     = {A Tutorial on Principal Component Analysis},
	journal   = {CoRR},
	volume    = {abs/1404.1100},
	year      = {2014},
	url       = {http://arxiv.org/abs/1404.1100},
	archivePrefix = {arXiv},
	eprint    = {1404.1100},
	timestamp = {Wed, 07 Jun 2017 14:40:25 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/Shlens14},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{Inceptionv4,
	author    = {Christian Szegedy and
	Sergey Ioffe and
	Vincent Vanhoucke},
	title     = {Inception-v4, Inception-ResNet and the Impact of Residual Connections
	on Learning},
	journal   = {CoRR},
	volume    = {abs/1602.07261},
	year      = {2016},
	url       = {http://arxiv.org/abs/1602.07261},
	archivePrefix = {arXiv},
	eprint    = {1602.07261},
	timestamp = {Wed, 07 Jun 2017 14:42:58 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/SzegedyIV16},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{VGG,
	author    = {Karen Simonyan and
	Andrew Zisserman},
	title     = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
	journal   = {CoRR},
	volume    = {abs/1409.1556},
	year      = {2014},
	url       = {http://arxiv.org/abs/1409.1556},
	archivePrefix = {arXiv},
	eprint    = {1409.1556},
	timestamp = {Wed, 07 Jun 2017 14:41:51 +0200},
	biburl    = {https://dblp.org/rec/bib/journals/corr/SimonyanZ14a},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{ILSVRC15,
	Author = {Olga Russakovsky and Jia Deng and Hao Su and Jonathan Krause and Sanjeev Satheesh and Sean Ma and Zhiheng Huang and Andrej Karpathy and Aditya Khosla and Michael Bernstein and Alexander C. Berg and Li Fei-Fei},
	Title = {{ImageNet Large Scale Visual Recognition Challenge}},
	Year = {2015},
	journal   = {International Journal of Computer Vision (IJCV)},
	doi = {10.1007/s11263-015-0816-y},
	volume={115},
	number={3},
	pages={211-252}
}
@misc{AVSP,
	author = {Toni Vlaić, Viran Ribić, Lucija Šikić},
	title = {Extracting Deep Features for Image Recommendation},
	year = {2016},
	publisher = {GitHub},
	journal = {GitHub repository},
	howpublished = {\url{https://github.com/Mungosin/AVSP}},
	commit = {b9e1963205483ebe6996cf46b76c15333df77c09}
}

@article{CS231n,
	title= {CS231n: Convolutional Neural Networks for Visual Recognition 2016},
	keywords= {},
	journal= {},
	author= {Fei-Fei Li and Andrej Karpathy and Justin Johnson},
	year= {},
	url= {http://cs231n.stanford.edu/},
	license= {},
	abstract= {Course Description
	Computer Vision has become ubiquitous in our society, with applications in search, image understanding, apps, mapping, medicine, drones, and self-driving cars. Core to many of these applications are visual recognition tasks such as image classification, localization and detection. Recent developments in neural network (aka “deep learning”) approaches have greatly advanced the performance of these state-of-the-art visual recognition systems. This course is a deep dive into details of the deep learning architectures with a focus on learning end-to-end models for these tasks, particularly image classification. During the 10-week course, students will learn to implement, train and debug their own neural networks and gain a detailed understanding of cutting-edge research in computer vision. The final assignment will involve training a multi-million parameter convolutional neural network and applying it on the largest image classification dataset (ImageNet). We will focus on teaching how to set up the problem of image recognition, the learning algorithms (e.g. backpropagation), practical engineering tricks for training and fine-tuning the networks and guide the students through hands-on assignments and a final course project. Much of the background and materials of this course will be drawn from the ImageNet Challenge.},
	superseded= {},
	terms= {}
}

@article{DubokoUcenje,
	title= {Neslužbene stranice predmeta Duboko učenje},
	keywords= {},
	journal= {},
	author= {Siniša Šegvić},
	year= {},
	url= {http://www.zemris.fer.hr/~ssegvic/du/},
	license= {},
	abstract= {Duboko učenje je grana strojnog učenja koja je posebno prikladna za rješavanje problema iz područja umjetne inteligencije. Duboko učenje se temelji na predstavljanju podataka složenim reprezentacijama do kojih se dolazi slijedom naučenih nelinearnih transformacija. Metode dubokog učenja svoju primjenu pronalaze u izazovnim područjima gdje je dimenzionalnost podataka iznimno velika: računalnom vidu, obradi prirodnog jezika ili razumijevanju govora. Ovaj predmet uvodi najvažnije diskriminativne i generativne duboke modele s posebnim naglaskom na praktične implementacije.
	
	Prva cjelina daje pregled ključnih elemenata klasičnih neuronskih mreža te uvodi osnovne građevne elemente, tehnike regularizacije i metode učenja koji su specifični za duboke modele. Druga cjelina razmatra duboke konvolucijske modele i ilustrira njihovu primjenu u klasifikaciji slika i obradi prirodnog jezika. Treća cjelina je posvećena generativnim dubokim modelima i njihovim primjenama u računalnom vidu i obradi prirodnog jezika. Konačno, četvrta cjelina razmatra modeliranje slijedova dubokim povratnim neuronskim mrežama i ilustrira primjene u području obrade prirodnog jezika.
	
	Svi koncepti popraćeni su primjerima i zadatcima u programskom jeziku Python. Većina primjera biti će vezana uz suvremeni aplikacijski okvir Tensorflow.
	
	Predmet se sastoji od tri sata predavanja tjedno, te laboratorijskih vježbi koje se kolokviraju jednom u svakom od četiri ciklusa. Predmet za sada nema preduvjeta, ali pretpostavlja se solidno znanje iz domena strojnog učenja, optimizacije, vjerojatnosti i linearne algebre stečena na prethodnim kolegijima.},
	superseded= {},
	terms= {}
}


@book{deeplearningbook,
	title={Deep Learning},
	author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
	publisher={MIT Press},
	note={\url{http://www.deeplearningbook.org}},
	year={2016}
}